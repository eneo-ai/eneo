# ============================================================================
# ENEO BACKEND ENVIRONMENT CONFIGURATION - PRODUCTION DEPLOYMENT
# ============================================================================
# This template is for production Docker deployments using docker-compose.yml
# Copy values from your development .env or configure for your environment
# ============================================================================

# ----------------------------------------------------------------------------
# Infrastructure (REQUIRED)
# ----------------------------------------------------------------------------
# PostgreSQL database
POSTGRES_USER=postgres
POSTGRES_PASSWORD=changeme    # CHANGE THIS FOR PRODUCTION!
POSTGRES_PORT=5432
POSTGRES_HOST=db              # Docker service name
POSTGRES_DB=eneo

# Redis cache
REDIS_HOST=redis              # Docker service name
REDIS_PORT=6379

# ----------------------------------------------------------------------------
# Security (REQUIRED)
# ----------------------------------------------------------------------------
API_PREFIX=/api/v1
API_KEY_LENGTH=64
API_KEY_HEADER_NAME=X-API-Key
JWT_AUDIENCE=*
JWT_ISSUER=ENEO
JWT_EXPIRY_TIME=86400
JWT_ALGORITHM=HS256

# JWT_SECRET - CRITICAL FOR PRODUCTION
# Signs OIDC state tokens and user authentication tokens
# WARNING: MUST be changed from default for production!
# Minimum strength: 32 characters (256+ bits)
# Generate strong secret: python -c 'import secrets; print(secrets.token_hex(32))'
JWT_SECRET=

JWT_TOKEN_PREFIX=Bearer
URL_SIGNING_KEY=

# ----------------------------------------------------------------------------
# Authentication Configuration
# ----------------------------------------------------------------------------
# Choose ONE of two modes:
#   1. Single-Tenant OIDC: One shared IdP for all users (recommended for most)
#   2. Multi-Tenant Federation: Each tenant has their own IdP (enterprise)
# ----------------------------------------------------------------------------

# PUBLIC_ORIGIN (REQUIRED for OIDC authentication)
# The externally-reachable URL where users access Eneo
# Used to construct OIDC redirect_uri (e.g., {PUBLIC_ORIGIN}/auth/callback)
# Must match:
#   1. What users see in their browser address bar
#   2. What's registered in your OIDC provider (Auth0, Azure AD, etc.)
#   3. Frontend PUBLIC_ORIGIN setting
# Examples:
#   Production: PUBLIC_ORIGIN=https://eneo.yourdomain.com
PUBLIC_ORIGIN=

# SINGLE-TENANT OIDC MODE (Default - Recommended)
# Direct login via one identity provider for all users
# ----------------------------------------------------------------------------
# OIDC discovery endpoint URL (auto-configures authorization/token/jwks endpoints)
# Examples:
#   Auth0: https://{your-domain}.auth0.com/.well-known/openid-configuration
#   Azure/Entra ID: https://login.microsoftonline.com/{tenant-id}/v2.0/.well-known/openid-configuration
#   Keycloak: https://{keycloak-url}/realms/{realm-name}/.well-known/openid-configuration
OIDC_DISCOVERY_ENDPOINT=

# OIDC client credentials (from your IdP application registration)
OIDC_CLIENT_ID=
OIDC_CLIENT_SECRET=

# [OPTIONAL] OIDC tenant ID (for backward compatibility with user creation)
OIDC_TENANT_ID=

# MULTI-TENANT FEDERATION MODE (Enterprise Only)
# Enable per-tenant identity providers (each tenant configures their own IdP)
# Requires ENCRYPTION_KEY and tenant configuration via sysadmin API
# ----------------------------------------------------------------------------
FEDERATION_PER_TENANT_ENABLED=false

# OIDC Safety Controls
# ----------------------------------------------------------------------------
# [OPTIONAL] OIDC state JWT lifetime (default: 600 = 10 minutes)
OIDC_STATE_TTL_SECONDS=600

# [OPTIONAL] Grace period for redirect URI changes (default: 600 = 10 minutes)
OIDC_REDIRECT_GRACE_PERIOD_SECONDS=600

# [OPTIONAL] Strict redirect URI validation (default: true)
STRICT_OIDC_REDIRECT_VALIDATION=true

# [OPTIONAL] Clock drift tolerance for OIDC JWT validation (default: 120 seconds)
OIDC_CLOCK_LEEWAY_SECONDS=120

# ----------------------------------------------------------------------------
# Encryption & Multi-Tenant Features
# ----------------------------------------------------------------------------
# ENCRYPTION_KEY is REQUIRED when enabling:
#   - TENANT_CREDENTIALS_ENABLED=true (tenant-specific LLM API keys)
#   - FEDERATION_PER_TENANT_ENABLED=true (tenant-specific IdPs)
#
# Generate key:
#   Development: uv run python -m intric.cli.generate_encryption_key
#   Production:  docker compose run --rm backend python -m intric.cli.generate_encryption_key
#   Alternative: python -c 'from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())'
#
# Format: 44-character base64-encoded Fernet key
# Example: FNVdDyfq0lBPAvjz_WS-9PB2UQzkbqCnwuA4KU9UbPU=
# WARNING: Backup this key securely - cannot decrypt without it
# ----------------------------------------------------------------------------
ENCRYPTION_KEY=

# Tenant-specific LLM credentials
# Enable municipalities to configure their own API keys per tenant
TENANT_CREDENTIALS_ENABLED=false

# ----------------------------------------------------------------------------
# LLM Provider API Keys (REQUIRED - At least ONE provider)
# ----------------------------------------------------------------------------
# Behavior depends on TENANT_CREDENTIALS_ENABLED setting:
#
# STRICT MODE (TENANT_CREDENTIALS_ENABLED=true):
#   - Tenant has configured key → tenant key is used
#   - Tenant has NO key → ERROR (no fallback to global)
#   - Tenant key is INVALID → ERROR (no fallback to global)
#
# SINGLE-TENANT MODE (TENANT_CREDENTIALS_ENABLED=false):
#   - Tenant has configured key → tenant key is used
#   - Tenant has NO key → global key is used (fallback)
#   - Tenant key is INVALID → ERROR (no fallback to global)
# ----------------------------------------------------------------------------

# OpenAI (GPT models)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Anthropic (Claude models)
# Get from: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# Azure OpenAI (Requires ALL 4 fields)
AZURE_API_KEY=
AZURE_ENDPOINT=
AZURE_API_BASE=
AZURE_MODEL_DEPLOYMENT=
AZURE_API_VERSION=2024-02-15-preview

# Other LLM Providers
MISTRAL_API_KEY=
OVHCLOUD_API_KEY=

# Berget.ai (Swedish-hosted models)
BERGET_API_KEY=
BERGET_API_BASE=

# GDM.se (Swedish AI provider)
# Get from: https://ai.gdm.se/
GDM_API_KEY=
# GDM_API_BASE=https://ai.gdm.se/api/v1  # Optional: Override default base URL

# Flux (Image generation)
FLUX_API_KEY=

# Tavily (Web search)
TAVILY_API_KEY=

# Self-hosted services
INFINITY_URL=

# vLLM (Self-hosted models)
VLLM_MODEL_URL=
VLLM_API_KEY=

# Internal services
INTRIC_MARKETPLACE_API_KEY=
INTRIC_MARKETPLACE_URL=
INTRIC_SUPER_API_KEY=
INTRIC_SUPER_DUPER_API_KEY=

# ----------------------------------------------------------------------------
# Background Worker Configuration
# ----------------------------------------------------------------------------
# Controls ARQ worker pool behavior and per-tenant concurrency fairness
#
# NOTE: RUN_AS_WORKER is set in docker-compose.yml to run the container as
# a background task processor instead of HTTP server. Both backend and worker
# containers use the same image; run.sh detects RUN_AS_WORKER=true to launch
# the ARQ worker instead of Gunicorn.
#
# VOLUMES: Ensure both backend and worker services have these volumes in docker-compose.yml:
#   - eneo_backend_data:/app/data
#   - eneo_temp_files:/tmp  # Also used for audit log exports (/tmp/exports)
# ----------------------------------------------------------------------------

# [OPTIONAL] Max concurrent jobs across all tenants (default: 20)
# Memory impact: Each job uses 100-500MB depending on task type
# Recommendation: 10-15 for <8GB RAM, 20+ for 16GB+ RAM
WORKER_MAX_CONCURRENT_JOBS=20

# [OPTIONAL] Max concurrent jobs per tenant (default: 4)
# Prevents one tenant from monopolizing worker slots
TENANT_WORKER_CONCURRENCY_LIMIT=4

# [OPTIONAL] Semaphore TTL - auto-cleanup for crashed workers (default: 36000 = 10 hours)
# Keep >= CRAWL_MAX_LENGTH so long crawls never drop their semaphore key
TENANT_WORKER_SEMAPHORE_TTL_SECONDS=36000

# [OPTIONAL] Retry delay when tenant hits limit (default: 30 seconds)
# Base delay for exponential backoff: 30s → 60s → 90s → ...
TENANT_WORKER_RETRY_DELAY_SECONDS=30

# [OPTIONAL] Crawl job age limit - Prevents infinite retry loops (default: 1800 = 30 min)
# Jobs permanently fail if still retrying after this duration
# Protects against cascading failures during burst crawl periods (e.g., 2 AM scheduled crawls)
CRAWL_JOB_MAX_AGE_SECONDS=1800

# ----------------------------------------------------------------------------
# Crawl Feeder Service (OPTIONAL - Prevents Burst Overload)
# ----------------------------------------------------------------------------
# The feeder service meters job enqueue rate to prevent overwhelming the worker
# queue when schedulers trigger (e.g., 50 websites at 2 AM causing retry storms)
#
# When enabled: Scheduler adds jobs to pending queue, feeder enqueues when capacity exists
# When disabled: Scheduler enqueues directly to ARQ (original behavior)
# ----------------------------------------------------------------------------

# [OPTIONAL] Enable feeder service (default: false for gradual rollout)
# Keep false until tested in your production environment
CRAWL_FEEDER_ENABLED=false

# [OPTIONAL] Feeder check interval (default: 10 seconds)
# How often the feeder checks for pending jobs and available capacity
CRAWL_FEEDER_INTERVAL_SECONDS=10

# [OPTIONAL] Feeder batch size (default: 10 jobs per cycle per tenant)
# Maximum jobs to enqueue per tenant per feeder cycle
# Prevents enqueueing entire queue at once if large capacity suddenly available
CRAWL_FEEDER_BATCH_SIZE=10

# ----------------------------------------------------------------------------
# Crawl Reliability & Recovery
# ----------------------------------------------------------------------------
# These settings prevent "Crawl already in progress" blocking and enable
# safe recovery from crashed workers or stuck jobs
# ----------------------------------------------------------------------------

# [OPTIONAL] Orphan crawl run cleanup timeout (default: 6 hours)
# Marks stuck QUEUED/IN_PROGRESS crawl runs as FAILED after this duration
# Prevents "Crawl already in progress" blocking new crawls indefinitely
# Higher values are safer for large websites; lower values provide faster cleanup
ORPHAN_CRAWL_RUN_TIMEOUT_HOURS=6

# [OPTIONAL] Safe preemption threshold for user-initiated recrawls (default: 30 min)
# When a user triggers a recrawl but an existing job is QUEUED/IN_PROGRESS:
#   - Job's last activity OLDER than threshold → job is "stale", marked FAILED, new crawl starts
#   - Job's last activity NEWER than threshold → job is "active", user gets error
# The worker sends heartbeats (see below) to keep active jobs alive
# 30 minutes is safe for most; increase for very large sites (>5000 pages)
CRAWL_STALE_THRESHOLD_MINUTES=30

# [OPTIONAL] Heartbeat interval for crawl jobs (default: 300 seconds = 5 min)
# During crawl, worker updates job's updated_at timestamp periodically
# This "heartbeat" signals the job is alive, preventing false-positive staleness
# TIME-BASED (not page-count-based) to handle slow-loading pages correctly
# Should be significantly less than CRAWL_STALE_THRESHOLD_MINUTES
CRAWL_HEARTBEAT_INTERVAL_SECONDS=300

# ----------------------------------------------------------------------------
# Audit Log Export Configuration
# ----------------------------------------------------------------------------
# [OPTIONAL] Directory for storing audit log export files
# Default: /tmp/exports (uses existing /tmp volume, no extra config needed)
# The /tmp directory is world-writable and already mounted via eneo_temp_files volume
# Override only if you need a custom location with appropriate permissions
# Check logs for "[EXPORT CONFIG]" messages if exports aren't working
# EXPORT_DIR=/tmp/exports

# [OPTIONAL] Max concurrent exports per tenant (default: 2)
# Prevents one tenant from overloading the system with many exports
EXPORT_MAX_CONCURRENT_PER_TENANT=2

# [OPTIONAL] Export file retention period in hours (default: 24)
# Files older than this are automatically cleaned up by daily cron job (03:00 UTC)
EXPORT_MAX_AGE_HOURS=24

# ----------------------------------------------------------------------------
# Feature Flags
# ----------------------------------------------------------------------------
USING_ACCESS_MANAGEMENT=True
USING_AZURE_MODELS=False
USING_IAM=False
USING_IMAGE_GENERATION=False
USING_CRAWL=True
TESTING=False
DEV=False

# ----------------------------------------------------------------------------
# File Upload Limits (bytes)
# ----------------------------------------------------------------------------
UPLOAD_FILE_TO_SESSION_MAX_SIZE=10485760
UPLOAD_IMAGE_TO_SESSION_MAX_SIZE=10485760
UPLOAD_MAX_FILE_SIZE=10485760
TRANSCRIPTION_MAX_FILE_SIZE=10485760
MAX_IN_QUESTION=1

# ----------------------------------------------------------------------------
# Web Crawling Configuration
# ----------------------------------------------------------------------------
# [OPTIONAL] Max crawl duration (default: 14400 = 4 hours)
CRAWL_MAX_LENGTH=14400
# [OPTIONAL] Max items before stopping (default: 20000)
CLOSESPIDER_ITEMCOUNT=20000
# [OPTIONAL] Max file download size in bytes (default: 10485760 = 10MB)
# Separate from UPLOAD_MAX_FILE_SIZE - controls crawler's DOWNLOAD_MAXSIZE
DOWNLOAD_MAX_SIZE=10485760
# [OPTIONAL] Respect robots.txt (default: True)
OBEY_ROBOTS=True
# [OPTIONAL] Auto-throttle requests (default: True)
AUTOTHROTTLE_ENABLED=True

# ----------------------------------------------------------------------------
# Integration OAuth Callbacks
# ----------------------------------------------------------------------------
OAUTH_CALLBACK_URL=
CONFLUENCE_CLIENT_ID=
CONFLUENCE_CLIENT_SECRET=
SHAREPOINT_CLIENT_ID=
SHAREPOINT_CLIENT_SECRET=

# ----------------------------------------------------------------------------
# Default Tenant & User (OPTIONAL - First-time Bootstrap Only)
# ----------------------------------------------------------------------------
# Uncomment these ONLY for initial deployment to create a default tenant/user
# After first deployment, comment them out or remove them
# WARNING: If left enabled, uses these values on every init_db run (but skips if already exists)
# ----------------------------------------------------------------------------
# DEFAULT_TENANT_NAME=YourOrganization
# DEFAULT_TENANT_QUOTA_LIMIT=10737418240
# DEFAULT_USER_NAME=Admin User
# DEFAULT_USER_EMAIL=admin@yourdomain.com
# DEFAULT_USER_PASSWORD=ChangeMe123!

# ----------------------------------------------------------------------------
# Migration & Maintenance
# ----------------------------------------------------------------------------
# Auto-recalculate usage stats threshold for model migrations
MIGRATION_AUTO_RECALC_THRESHOLD=30

# ----------------------------------------------------------------------------
# Logging
# ----------------------------------------------------------------------------
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Recommended for production: INFO
LOGLEVEL=INFO

# ----------------------------------------------------------------------------
# DEPRECATED: MobilityGuard and Zitadel variables are no longer used.
# Use OIDC_DISCOVERY_ENDPOINT, OIDC_CLIENT_ID, and OIDC_CLIENT_SECRET above.
# ----------------------------------------------------------------------------
